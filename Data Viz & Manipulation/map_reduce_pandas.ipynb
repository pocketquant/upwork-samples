{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Define the map function\n",
    "def map_function(data):\n",
    "    intermediate_key_value_pairs = []\n",
    "    for index, row in data.iterrows():\n",
    "        key = row['timestamp']\n",
    "        value = row['value']\n",
    "        intermediate_key_value_pairs.append((key, value))\n",
    "    return intermediate_key_value_pairs\n",
    "\n",
    "# Define the reduce function\n",
    "def reduce_function(key, values):\n",
    "    return sum(values)\n",
    "\n",
    "# Split the data into 1 minute increments\n",
    "grouped_data = df.groupby(pd.Grouper(key='timestamp', freq='1min'))\n",
    "\n",
    "# Initialize the defaultdict that will store the intermediate key-value pairs\n",
    "intermediate_key_value_pairs = defaultdict(list)\n",
    "\n",
    "# Apply the map function to each group of data\n",
    "for group in grouped_data:\n",
    "    key, data = group\n",
    "    intermediate_key_value_pairs[key].extend(map_function(data))\n",
    "\n",
    "# Initialize the defaultdict that will store the final key-value pairs\n",
    "final_key_value_pairs = defaultdict(list)\n",
    "\n",
    "# Apply the reduce function to each set of intermediate key-value pairs\n",
    "for key, values in intermediate_key_value_pairs.items():\n",
    "    final_key_value_pairs[key] = reduce_function(key, values)\n",
    "\n",
    "# Print the final key-value pairs\n",
    "print(final_key_value_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## can you use mapreduce to perform a function on every 1 minute increment of a pandas dataframe?\n",
    "\n",
    "\n",
    "\n",
    "yes, it is possible to use MapReduce to perform a function on every 1 minute increment of a Pandas dataframe.\n",
    "\n",
    "Here is an example of how this could be done:\n",
    "\n",
    "First, you would need to split the dataframe into chunks of data corresponding to 1 minute increments. This can be done by grouping the data by the timestamp column and applying the function to each group.\n",
    "\n",
    "Next, you would need to define the \"map\" function that will be applied to each group of data. This function should take a group of data as input and return a set of intermediate key-value pairs.\n",
    "\n",
    "You would then need to define the \"reduce\" function that will be used to merge the intermediate key-value pairs produced by the map function. This function should take a key and a list of values as input and return a single, aggregated value.\n",
    "\n",
    "Finally, you can use the MapReduce function provided by the Apache Hadoop project to parallelize the execution of the map and reduce functions across a cluster of machines.\n",
    "\n",
    "Here is some example code that demonstrates how this could be done:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
