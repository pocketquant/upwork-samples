{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import requests ,json\n",
    "\n",
    "async def get_pokemon(session, url):\n",
    "    async with session.get(url) as resp:\n",
    "        pokemon = await resp.json()\n",
    "        return pokemon['name']\n",
    "        # return pokemon\n",
    "# format for requesting data \n",
    "# r = requests.get(BAR_URL_2, headers=config.HEADERS)\n",
    "# SNAPSHOTS_URL = 'https://data.alpaca.markets/v2/stocks/snapshots?symbols=TSLA,AMZN'\n",
    "# BAR_URL_2 = 'https://data.alpaca.markets/v2/stocks/SPY/bars?start=2022-01-01T09:30:00.00-04:00&end=2022-04-08T16:30:00.00-04:00&limit=1&timeframe=5Min'\n",
    "_date = '2022-10-20'\n",
    "\n",
    "_ticker = \"SPY\"\n",
    "_limit = 10000\n",
    "TRADES_URL = f'https://data.alpaca.markets/v2/stocks/{_ticker}/trades?start={_date}&end={_date}&limit={_limit}'\n",
    "r = requests.get(TRADES_URL, headers=HEADERS)\n",
    "print(json.dumps(r.json(),indent=4))\n",
    "\n",
    "\n",
    "async def main():\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "\n",
    "        tasks = []\n",
    "        for number in range(1, 151):\n",
    "            url = f'https://pokeapi.co/api/v2/pokemon/{number}'\n",
    "            tasks.append(asyncio.ensure_future(get_pokemon(session, url)))\n",
    "\n",
    "        original_pokemon = await asyncio.gather(*tasks)\n",
    "        for pokemon in original_pokemon:\n",
    "            print(pokemon)\n",
    "\n",
    "\n",
    "# asyncio.run(main())\n",
    "\n",
    "#TODO\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date range algo here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import aiohttp\n",
    "import asyncio\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=API_URL)\n",
    "# Docs for Async\n",
    "# https://builtin.com/data-science/asyncio-python\n",
    "# _misc = 'tryit'\n",
    "# _str = f'http//:{_misc}'\n",
    "# _str\n",
    "\n",
    "# Need all days for bitcoin and crypto \n",
    "# TODO stocks doesn't use all days \n",
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "date_list = []\n",
    "# Short time to test\n",
    "start_dt = date(2022, 10, 20)\n",
    "end_dt = date(2022, 10, 21)\n",
    "for dt in daterange(start_dt, end_dt):\n",
    "    # global date_list\n",
    "    day_string = dt.strftime(\"%Y-%m-%d\")\n",
    "    date_list.append(day_string)\n",
    "\n",
    "ticker = \"SPY\"\n",
    "print(date_list)\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for day_date in date_list:\n",
    "            task = asyncio.ensure_future(get_daily_dataframe(session, day_date))\n",
    "            # df = pd.concat([df,day_dataframe])\n",
    "            tasks.append(task)\n",
    "\n",
    "        # view_counts = await asyncio.gather(*tasks)\n",
    "        return await asyncio.gather(*tasks)\n",
    "        # return await df\n",
    "\n",
    "async def get_daily_dataframe(session, day_date):\n",
    "    # url = f'https://www.googleapis.com/youtube/v3/videos?id={video_id}&key={key}&part=statistics'\n",
    "    df =  api.get_trades(ticker,day_date, day_date).df\n",
    "    return  df \n",
    "    # async with  api.get_trades(ticker,day_date, day_date).df as df:\n",
    "\n",
    "    #     # result_data = await response.json()\n",
    "    #     # results = result_data['items']\n",
    "    #     # viewCount = results[0]['statistics']['viewCount']\n",
    "    #     return df\n",
    "async_result = await main() \n",
    "async_result \n",
    "# TODO -> USE json , combine json , then put in a dataframe\n",
    "\n",
    "#HTTP REQUEST FORMAT\n",
    "# df = api.get_trades(\"SPY\", \"2022-10-10\", \"2022-10-12\").df\n",
    "# df = df.reindex(columns= [ 'price', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async API Data Requests\n",
    "IQfeed has a 50 request limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import requests ,json\n",
    "# import pandas as pd\n",
    "# _date = '2022-10-20'\n",
    "_date = '2022-10-20'\n",
    "_ticker = \"SPY\"\n",
    "_limit = 10000\n",
    "_url = f'https://data.alpaca.markets/v2/stocks/{_ticker}/trades?start={_date}&end={_date}&limit={_limit}'\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "while True:\n",
    "    global df_test\n",
    "    r = requests.get(_url ,headers=HEADERS)\n",
    "    results = r.json()\n",
    "    if 'next_page_token' in results:\n",
    "        nextPageToken = results['next_page_token']\n",
    "    else:\n",
    "        nextPageToken = None\n",
    "    \n",
    "    # if 'items' in results:\n",
    "    #     for item in results['items']:\n",
    "    #         videoId = item['contentDetails']['videoId']\n",
    "    #         video_ids.append(videoId)\n",
    "\n",
    "    if nextPageToken:\n",
    "        # url = f'https://www.googleapis.com/youtube/v3/playlistItems?playlistId={playlist_id}&pageToken={nextPageToken}&key={key}&part=contentDetails&maxResults=50'\n",
    "        _url = f'https://data.alpaca.markets/v2/stocks/{_ticker}/trades?start={_date}&end={_date}&limit={_limit}&page_token={nextPageToken}'\n",
    "    else:\n",
    "        break\n",
    "    # print(len(results))\n",
    "    # print(len(results['trades']))\n",
    "    trades = results['trades']\n",
    "    # df = pd.read_json(results['trades'][0])\n",
    "    df = pd.DataFrame.from_records(trades)\n",
    "    df_test = pd.concat([df_test, df])\n",
    "    # print(df)\n",
    "    # break\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if results['nextPageToken'] in results:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '{\"col1\":{\"row1\":1,\"row2\":2,\"row3\":3},\"col2\":{\"row1\":\"x\",\"row2\":\"y\",\"row3\":\"z\"}}'\n",
    "pd.read_json(s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b54d6a16add27ca2e677aa06196fc1ec2f82f9925cd5147b5e0b38cd001f612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
